{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f292b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import logging\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import torch\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from collections import OrderedDict\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.engine import DefaultTrainer, default_argument_parser, default_setup, hooks, launch\n",
    "from detectron2.evaluation import (\n",
    "    COCOEvaluator,\n",
    "    DatasetEvaluators,\n",
    "    verify_results,\n",
    ")\n",
    "from detectron2.modeling import GeneralizedRCNNWithTTA\n",
    "\n",
    "from detectron2.data.build import build_detection_test_loader\n",
    "from detectron2.engine import HookBase\n",
    "from detectron2.engine.hooks import PeriodicWriter\n",
    "\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data.dataset_mapper import DatasetMapper\n",
    "from detectron2.data.build import (_test_loader_from_config, build_detection_train_loader)\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b21e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"street_train\", {}, \"path_to_annotations/annotations_train.json\", \"path_to_images/images\")\n",
    "register_coco_instances(\"street_val\", {}, \"path_to_annotations/annotations_val.json\", \"path_to_images/images\")\n",
    "register_coco_instances(\"street_test\", {}, \"path_to_annotations/annotations_test.json\", \"path_to_images/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ac112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize training data\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"street_train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"street_train\")\n",
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    print(d[\"file_name\"])\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(vis.get_image()[:, :, ::1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be63c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_evaluator(cfg, dataset_name, output_folder=None):\n",
    "    \"\"\"\n",
    "    Create evaluator(s) for a given dataset.\n",
    "    This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n",
    "    For your own dataset, you can simply create an evaluator manually in your\n",
    "    script and do not have to worry about the hacky if-else logic here.\n",
    "    \"\"\"\n",
    "    if output_folder is None:\n",
    "        output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "    evaluator_list = []\n",
    "    evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type\n",
    "    if evaluator_type in [\"coco\"]:\n",
    "        evaluator_list.append(COCOEvaluator(dataset_name, output_dir=output_folder))\n",
    "    if len(evaluator_list) == 0:\n",
    "        raise NotImplementedError(\n",
    "            \"no Evaluator for the dataset {} with the type {}\".format(dataset_name, evaluator_type)\n",
    "        )\n",
    "    elif len(evaluator_list) == 1:\n",
    "        return evaluator_list[0]\n",
    "    return DatasetEvaluators(evaluator_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c64b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "class ValLossHook(HookBase):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg.clone()\n",
    "        self._loader = cycle(build_detection_test_loader(self.cfg, \"street_val\", DatasetMapper(self.cfg,True)))\n",
    "        \n",
    "    def after_step(self):\n",
    "        \"\"\"\n",
    "            After each step calculates the validation loss and adds it to the train storage\n",
    "        \"\"\"\n",
    "        data = next(self._loader)\n",
    "#         print(len(data))\n",
    "        with torch.no_grad():\n",
    "            loss_dict = self.trainer.model(data)\n",
    "            \n",
    "            losses = sum(loss_dict.values())\n",
    "            assert torch.isfinite(losses).all(), loss_dict\n",
    "\n",
    "            loss_dict_reduced = {\"val_\" + k: v.item() for k, v in comm.reduce_dict(loss_dict).items()}\n",
    "            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "            if comm.is_main_process():\n",
    "                self.trainer.storage.put_scalars(val_total_loss=losses_reduced, \n",
    "                                                 **loss_dict_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b906ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from detectron2.utils.events import EventWriter, get_event_storage, CommonMetricPrinter, JSONWriter\n",
    "\n",
    "class CustomTensorboardXWriter(EventWriter):\n",
    "    \"\"\"\n",
    "    Writes scalars and images based on storage key to train or val tensorboard file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_dir: str, window_size: int = 20, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            log_dir (str): the base directory to save the output events. This class creates two subdirs in log_dir\n",
    "            window_size (int): the scalars will be median-smoothed by this window size\n",
    "\n",
    "            kwargs: other arguments passed to `torch.utils.tensorboard.SummaryWriter(...)`\n",
    "        \"\"\"\n",
    "        self._window_size = window_size\n",
    "        \n",
    "        # separate the writers into a train and a val writer\n",
    "        train_writer_path = os.path.join(log_dir,\"train\")\n",
    "        os.makedirs(train_writer_path, exist_ok=True)\n",
    "        self._writer_train = SummaryWriter(train_writer_path, **kwargs)\n",
    "        \n",
    "        val_writer_path = os.path.join(log_dir,\"val\")\n",
    "        os.makedirs(val_writer_path, exist_ok=True)\n",
    "        self._writer_val = SummaryWriter(val_writer_path, **kwargs)\n",
    "\n",
    "    def write(self):\n",
    "\n",
    "        storage = get_event_storage()\n",
    "        for k, (v, iter) in storage.latest_with_smoothing_hint(self._window_size).items():\n",
    "            if k.startswith(\"val_\"):\n",
    "                k = k.replace(\"val_\",\"\")\n",
    "                self._writer_val.add_scalar(k, v, iter)\n",
    "            else:\n",
    "                self._writer_train.add_scalar(k, v, iter)\n",
    "\n",
    "        if len(storage._vis_data) >= 1:\n",
    "            for img_name, img, step_num in storage._vis_data:\n",
    "                if k.startswith(\"val_\"):\n",
    "                    k = k.replace(\"val_\",\"\")\n",
    "                    self._writer_val.add_image(img_name, img, step_num)\n",
    "                else:\n",
    "                    self._writer_train.add_image(img_name, img, step_num)\n",
    "            # Storage stores all image data and rely on this writer to clear them.\n",
    "            # As a result it assumes only one writer will use its image data.\n",
    "            # An alternative design is to let storage store limited recent\n",
    "            # data (e.g. only the most recent image) that all writers can access.\n",
    "            # In that case a writer may not see all image data if its period is long.\n",
    "            storage.clear_images()\n",
    "\n",
    "        if len(storage._histograms) >= 1:\n",
    "            for params in storage._histograms:\n",
    "                self._writer_train.add_histogram_raw(**params)\n",
    "            storage.clear_histograms()\n",
    "\n",
    "    def close(self):\n",
    "        if hasattr(self, \"_writer\"):  # doesn't exist when the code fails at import\n",
    "            self._writer_train.close()\n",
    "            self._writer_val.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5d3a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(DefaultTrainer):\n",
    "    \"\"\"\n",
    "    We use the \"DefaultTrainer\" which contains pre-defined default logic for\n",
    "    standard training workflow. They may not work for you, especially if you\n",
    "    are working on a new research project. In that case you can write your\n",
    "    own training loop. You can use \"tools/plain_train_net.py\" as an example.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return build_evaluator(cfg, dataset_name, output_folder)\n",
    "    \n",
    "    def build_writers(self):\n",
    "        \"\"\"\n",
    "        Overwrites the default writers to contain our custom tensorboard writer\n",
    "\n",
    "        Returns:\n",
    "            list[EventWriter]: a list of :class:`EventWriter` objects.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            CommonMetricPrinter(self.max_iter),\n",
    "            JSONWriter(os.path.join(self.cfg.OUTPUT_DIR, \"metrics.json\")),\n",
    "            CustomTensorboardXWriter(self.cfg.OUTPUT_DIR),\n",
    "        ]\n",
    "\n",
    "    @classmethod\n",
    "    def test_with_TTA(cls, cfg, model):\n",
    "        logger = logging.getLogger(\"detectron2.trainer\")\n",
    "        # In the end of training, run an evaluation with TTA\n",
    "        # Only support some R-CNN models.\n",
    "        logger.info(\"Running inference with test-time augmentation ...\")\n",
    "        model = GeneralizedRCNNWithTTA(cfg, model)\n",
    "        evaluators = [\n",
    "            cls.build_evaluator(\n",
    "                cfg, name, output_folder=os.path.join(cfg.OUTPUT_DIR, \"inference_TTA\")\n",
    "            )\n",
    "            for name in cfg.DATASETS.TEST\n",
    "        ]\n",
    "        res = cls.test(cfg, model, evaluators)\n",
    "        res = OrderedDict({k + \"_TTA\": v for k, v in res.items()})\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf742ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"street_train\",)\n",
    "cfg.DATASETS.TEST = (\"street_val\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS=False\n",
    "cfg.OUTPUT_DIR = \"/home/ryzen/sriram/detectron2_res/plitterstreet/outputWithEval_23Feb2022\"\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001  \n",
    "cfg.SOLVER.MAX_ITER = 60000\n",
    "cfg.SOLVER.STEPS = (30000, 40000)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 1024\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD=5000\n",
    "# cfg.MODEL.DEVICE = \"cuda:0\"\n",
    "cfg.TEST.AUG.ENABLED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(cfg)\n",
    "trainer.register_hooks(\n",
    "    [ValLossHook(cfg), hooks.EvalHook(0, lambda: trainer.test_with_TTA(cfg, trainer.model))]\n",
    ")    \n",
    "\n",
    "periodic_writer_hook = [hook for hook in trainer._hooks if isinstance(hook, PeriodicWriter)]\n",
    "all_other_hooks = [hook for hook in trainer._hooks if not isinstance(hook, PeriodicWriter)]\n",
    "trainer._hooks = all_other_hooks + periodic_writer_hook\n",
    "trainer.resume_or_load(resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a93c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44eb86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate the trainer model\n",
    "\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"street_test\", cfg, False, output_dir=None)\n",
    "val_loader = build_detection_test_loader(cfg, \"street_test\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the predictor with setting score threshold\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"street_val\", output_dir=\"output_to_save\")\n",
    "val_loader = build_detection_test_loader(cfg, \"street_val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba25a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c2b112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import _create_text_labels\n",
    "import time, tqdm, json\n",
    "\n",
    "thing_colors = [(255, 255, 0), (255, 0, 0), (0, 0, 255), (0, 255, 0)]\n",
    "\n",
    "def runOnVideo(video, maxFrames):\n",
    "    \"\"\" Runs the predictor on every frame in the video (unless maxFrames is given),\n",
    "    and returns the frame with the predictions drawn.\n",
    "    \"\"\"\n",
    "\n",
    "    readFrames = 1\n",
    "    while True:\n",
    "        hasFrame, frame = video.read()\n",
    "        if not hasFrame:\n",
    "            break\n",
    "            \n",
    "        predictions = predictor(frame)\n",
    "        predictions = predictions[\"instances\"].to(\"cpu\")\n",
    "        visualizer = Visualizer(frame[:, :, ::-1], metadata=plitterstreet_test_metadata, scale=1)\n",
    "        \n",
    "        boxes = predictions.pred_boxes.tensor.numpy() if predictions.has(\"pred_boxes\") else None\n",
    "        scores = predictions.scores if predictions.has(\"scores\") else None\n",
    "        classes = predictions.pred_classes.numpy() if predictions.has(\"pred_classes\") else None\n",
    "        labels = _create_text_labels(classes, scores, plitterstreet_test_metadata.get(\"thing_classes\", None))\n",
    "        colors = [tuple(x/255 for x in thing_colors[c]) for c in classes]\n",
    "        \n",
    "#         vis = visualizer.draw_instance_predictions(predictions=outputs[\"instances\"].to(\"cpu\"))\n",
    "        visualizer.overlay_instances(\n",
    "            boxes = boxes,\n",
    "            masks = None,\n",
    "            labels = None,\n",
    "            keypoints = None,\n",
    "            assigned_colors = colors,\n",
    "            alpha = 1\n",
    "        )\n",
    "        vis = visualizer.output \n",
    "        \n",
    "        visualization = cv2.cvtColor(vis.get_image(), cv2.COLOR_RGB2BGR)\n",
    "        predictions_dict = {\"frameId\": readFrames, \"boxes\": boxes, \"scores\": scores, \"classes\": classes}\n",
    "        \n",
    "        yield visualization, predictions_dict\n",
    "\n",
    "        if readFrames > maxFrames:\n",
    "            break\n",
    "        readFrames += 1\n",
    "        \n",
    "def default(obj):\n",
    "    return obj.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import _create_text_labels\n",
    "import time, tqdm, json\n",
    "\n",
    "thing_colors = [(255, 255, 0), (255, 0, 0), (0, 0, 255), (0, 255, 0)]\n",
    "\n",
    "from deep_sort import DeepSort\n",
    "deepsort = DeepSort('deep_sort/deep/checkpoint/ckpt.t7', use_cuda=False)\n",
    "\n",
    "def runOnVideoWithdeepsort(video, maxFrames):\n",
    "    \"\"\" Runs the predictor on every frame in the video (unless maxFrames is given),\n",
    "    and returns the frame with the predictions drawn.\n",
    "    \"\"\"\n",
    "\n",
    "    readFrames = 1\n",
    "    while True:\n",
    "        hasFrame, frame = video.read()\n",
    "        if not hasFrame:\n",
    "            break\n",
    "            \n",
    "        predictions = predictor(frame)\n",
    "        predictions = predictions[\"instances\"].to(\"cpu\")\n",
    "        visualizer = Visualizer(frame[:, :, ::-1], metadata=plitterstreet_test_metadata, scale=1)\n",
    "        \n",
    "        boxes = predictions.pred_boxes.tensor.numpy() if predictions.has(\"pred_boxes\") else None\n",
    "        scores = predictions.scores if predictions.has(\"scores\") else None\n",
    "        classes = predictions.pred_classes.numpy() if predictions.has(\"pred_classes\") else None\n",
    "        \n",
    "        bbox_xcycwh, cls_conf, cls_ids = [], [], []\n",
    "\n",
    "        for (box, _class, score) in zip(boxes, classes, scores):\n",
    "            x0, y0, x1, y1 = box\n",
    "            bbox_xcycwh.append([(x1 + x0) / 2, (y1 + y0) / 2, (x1 - x0), (y1 - y0)])\n",
    "            cls_conf.append(score)\n",
    "            cls_ids.append(_class)\n",
    "        \n",
    "        boxes = np.array(bbox_xcycwh, dtype=np.float64)\n",
    "        scores = np.array(cls_conf)\n",
    "        classes = np.array(cls_ids)\n",
    "        \n",
    "        tboxes = []\n",
    "        tscores = []\n",
    "        tclasses = []\n",
    "        track_ids = []\n",
    "        outputs = deepsort.update(boxes, scores, classes, frame)\n",
    "        print(outputs)\n",
    "        if outputs != []:\n",
    "            tboxes = outputs[:, :4]\n",
    "            tscores = outputs[:, 4]\n",
    "            tclasses = outputs[:, 5]\n",
    "            track_ids = outputs[:, 6]\n",
    "        \n",
    "        if len(tboxes) != len(boxes):\n",
    "            print(tboxes, boxes, \"danger!!!!!!!!!!!!\")\n",
    "#             break\n",
    "        \n",
    "        labels = _create_text_labels(tclasses, tscores, plitterstreet_test_metadata.get(\"thing_classes\", None))\n",
    "        colors = [tuple(x/255 for x in thing_colors[c]) for c in tclasses]\n",
    "        \n",
    "#         vis = visualizer.draw_instance_predictions(predictions=outputs[\"instances\"].to(\"cpu\"))\n",
    "        visualizer.overlay_instances(\n",
    "            boxes = tboxes,\n",
    "            masks = None,\n",
    "            labels = labels,\n",
    "            keypoints = None,\n",
    "            assigned_colors = colors,\n",
    "            alpha = 1\n",
    "        )\n",
    "        vis = visualizer.output \n",
    "        \n",
    "        visualization = cv2.cvtColor(vis.get_image(), cv2.COLOR_RGB2BGR)\n",
    "        predictions_dict = {\"frameId\": readFrames, \"boxes\": tboxes, \"scores\": tscores, \"classes\": tclasses, \"track_ids\": track_ids}\n",
    "        \n",
    "        yield visualization, predictions_dict\n",
    "\n",
    "        if readFrames > maxFrames:\n",
    "            break\n",
    "        readFrames += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecdd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('/media/ryzen/DATA/Hanwella/January_2022/videos/GX010102.MP4')\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
    "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(width, height, frames_per_second, num_frames)\n",
    "\n",
    "video_writer = cv2.VideoWriter('/media/ryzen/DATA/Hanwella/January_2022/videos/outputs/GX010102_outputwithtrack.MP4', fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"), fps=float(frames_per_second), frameSize=(width, height), isColor=True)\n",
    "f = open(\"/media/ryzen/DATA/Hanwella/January_2022/videos/outputs/GX010102_outputwithtrack.json\", \"w\")\n",
    "predictions_json = []\n",
    "\n",
    "c = 1\n",
    "for visualization, predictions_dict in tqdm.tqdm(runOnVideoWithdeepsort(video, num_frames), total=num_frames):\n",
    "#     visualization = result[0]\n",
    "#     predictions_dict = result[1]\n",
    "    cv2.imwrite('/media/ryzen/DATA/Hanwella/January_2022/videos/check/'+str(c)+'.jpg', visualization)\n",
    "    video_writer.write(visualization)\n",
    "    predictions_json.append(predictions_dict)\n",
    "    c += 1\n",
    "\n",
    "\n",
    "json.dump({\"GX010102\": json.dumps(predictions_json, default=default)}, f)\n",
    "f.close()\n",
    "video.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25eea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_dir = '/media/ryzen/pLitter1/Ubon/January_2022/videos/1280/'\n",
    "videos_outdir = '/media/ryzen/pLitter1/Ubon/January_2022/videos/outputs/'\n",
    "for filename in sorted(os.listdir(videos_dir)):\n",
    "    if filename.endswith('.MP4') and filename not in os.listdir(videos_outdir):\n",
    "        print(filename)\n",
    "        video = cv2.VideoCapture(videos_dir+filename)\n",
    "        width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
    "        num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(width, height, frames_per_second, num_frames)\n",
    "\n",
    "        video_writer = cv2.VideoWriter(videos_outdir+filename, fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"), fps=float(frames_per_second), frameSize=(width, height), isColor=True)\n",
    "        f = open(videos_outdir+filename.replace('.MP4', '.json'), \"w\")\n",
    "        predictions_json = []\n",
    "\n",
    "        c = 1\n",
    "        for visualization, predictions_dict in tqdm.tqdm(runOnVideo(video, num_frames), total=num_frames):\n",
    "#             cv2.imwrite(videos_outdir+'check/'+str(c)+'.jpg', visualization)\n",
    "            video_writer.write(visualization)\n",
    "            predictions_json.append(predictions_dict)\n",
    "            c += 1\n",
    "\n",
    "\n",
    "        json.dump({filename.replace(\".MP4\", \"\"): json.dumps(predictions_json, default=default)}, f)\n",
    "        f.close()\n",
    "        video.release()\n",
    "        video_writer.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
