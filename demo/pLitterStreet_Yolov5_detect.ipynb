{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fphVxd3Ecu_3"
      },
      "source": [
        "Download the trained weights for plitterStreet detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iRoAAX31IoS"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/gicait/pLitter\n",
        "# !pip install /content/pLitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NovpojexZa7j"
      },
      "outputs": [],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1lRKR5SfjhmaWichmBg2TWPufUVDed4zF' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1lRKR5SfjhmaWichmBg2TWPufUVDed4zF\" -O /content/yolov5l.pt && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KByPyQ5xoy6"
      },
      "source": [
        "GoPro videos not working properly with opencv\n",
        "\n",
        "use ffmpeg to copy the video track to a new file \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JT3KhXdul1St"
      },
      "outputs": [],
      "source": [
        "# %cd 'directory_to_videos'\n",
        "\n",
        "# !for FILE in *.MP4; do ffmpeg -i $FILE -c:v copy \"target_dir_to_save_video_tracks\"/${FILE//MP4/mp4} -y; done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6DhE4HedCOE"
      },
      "outputs": [],
      "source": [
        "import os, cv2, json, time\n",
        "import torch\n",
        "# from plitterstreet.predict import draw_boxes_on_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89loTTiKGxtE"
      },
      "outputs": [],
      "source": [
        "colors = [(0,255,255), (0,0,255), (255,0,0), (0,255,0)]\n",
        "def draw_boxes_on_image(image, boxes, classes, class_ids, scores, use_normalized_coordinates=True, min_score_thresh=.3):\n",
        "    assert len(boxes) == len(scores) == len(classes)\n",
        "    for i in range(len(boxes)):\n",
        "        box = boxes[i]\n",
        "        category = str(classes[i])\n",
        "        class_id = int(class_ids[i])\n",
        "        score = scores[i]\n",
        "        if score >= min_score_thresh:\n",
        "          if use_normalized_coordinates:\n",
        "            h,w,_ = image.shape\n",
        "            y1 = int(box[0]*h)\n",
        "            x1 = int(box[1]*w)\n",
        "            y2 = int(box[2]*h)\n",
        "            x2 = int(box[3]*w)  \n",
        "          else:\n",
        "            x1,y1,x2,y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
        "          image = cv2.rectangle(image, (x1, y1), (x2, y2), colors[class_id], 2)\n",
        "          cv2.putText(image, category+':'+str(round(score,2)), (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[class_id], 1)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4YEHbmLddoN",
        "outputId": "54ab1690-5312-4adc-e9a1-22918b08760a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 ðŸš€ 2022-10-9 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5l summary: 367 layers, 46124433 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "weights = '/content/yolov5l.pt'\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', weights, force_reload=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R9V8GezzC2H"
      },
      "outputs": [],
      "source": [
        "# img = cv2.imread('/content/drive/MyDrive/roxana-charles-st-gopro-capture-sept30/GH010017/GH010017_10.jpg')\n",
        "# preds = model(img, size=1280)\n",
        "# class_ids = preds.xyxy[0].cpu().numpy()[:, 5]\n",
        "# classes = [preds.names[cls] for cls in class_ids]\n",
        "# scores = preds.xyxy[0].cpu().numpy()[:, 4]\n",
        "# boxes = preds.xyxy[0].cpu().numpy()[:,:4]\n",
        "# img = draw_boxes_on_image(img, boxes, classes, class_ids, scores, use_normalized_coordinates=False, min_score_thresh=.4)\n",
        "\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGATiKJ2yuOD"
      },
      "outputs": [],
      "source": [
        "source = 'folder_to_videos_to_detect'\n",
        "target = 'folder_to_save_detected_videos'\n",
        "\n",
        "# if source == target:\n",
        "#   print('source should not be same as )\n",
        "\n",
        "if os.path.isfile(source):\n",
        "  dataset = [os.path.basename(source)]\n",
        "  source = os.path.dirname(source)\n",
        "elif os.path.isdir(source):\n",
        "  dataset = sorted([im for im in os.listdir(source) if im.lower().endswith(('.mp4', '.avi', '.jpg', '.png'))])\n",
        "else:\n",
        "  print('please check source is correct')\n",
        "\n",
        "print(dataset)\n",
        "\n",
        "for fn in dataset[-2:-1]:\n",
        "  print(fn)\n",
        "  if fn.endswith(('.jpg', '.png')):\n",
        "    img = cv2.imread(os.path.join(source, fn))\n",
        "    preds = model(img, size=1280)\n",
        "    class_ids = preds.xyxy[0].cpu().numpy()[:, 5]\n",
        "    classes = [preds.names[cls] for cls in class_ids]\n",
        "    scores = preds.xyxy[0].cpu().numpy()[:, 4]\n",
        "    boxes = preds.xyxy[0].cpu().numpy()[:,:4]\n",
        "    img = draw_boxes_on_image(img, boxes, classes, class_ids, scores, use_normalized_coordinates=False, min_score_thresh=.4)\n",
        "    cv2.imwrite(os.path.join(target, fn), img)\n",
        "    pred_json = {'file_name': fn, 'category_ids': class_ids, 'boxes': boxes, 'scores': scores}\n",
        "    json.dump(pred_json, os.path.join(target, fn.replace(('.jpg', '.png'), '.json')))\n",
        "  else:\n",
        "    st = time.time()\n",
        "    vid = cv2.VideoCapture(os.path.join(source, fn))\n",
        "    width  = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
        "    # print(width, height)\n",
        "    # fn_r = os.path.join(target, fn.split('.')[0]+'.avi')\n",
        "    fn_r = os.path.join(target, fn)\n",
        "    print(fn_r)\n",
        "    # result = cv2.VideoWriter(fn_r, cv2.VideoWriter_fourcc(*'MJPG'), fps, (width, height))\n",
        "    result = cv2.VideoWriter(fn_r, cv2.VideoWriter_fourcc(*'MP4V'), fps, (width, height))\n",
        "    # result = cv2.VideoWriter(fn_r, cv2.VideoWriter_fourcc(*'H264'), fps, (width, height))\n",
        "    pred_json = {'video': fn, 'preds': []}\n",
        "    c = 1\n",
        "    while True:\n",
        "        ret, img = vid.read()\n",
        "        if img is None:\n",
        "          json.dump(pred_json, open(target+fn.replace('.MP4', '_result.json'), 'w'))\n",
        "          result.release()\n",
        "          vid.release()\n",
        "          break\n",
        "        preds = model(img, size=1280)\n",
        "        class_ids = preds.xyxy[0].cpu().numpy()[:, 5]\n",
        "        classes = [preds.names[cls] for cls in class_ids]\n",
        "        scores = preds.xyxy[0].cpu().numpy()[:, 4]\n",
        "        boxes = preds.xyxy[0].cpu().numpy()[:,:4]\n",
        "        im = draw_boxes_on_image(img, boxes, classes, class_ids, scores, use_normalized_coordinates=False, min_score_thresh=.4)\n",
        "        # cv2.imwrite('/content/frames/'+str(c)+'.jpg', im)\n",
        "        pred_json['preds'].append({'frame': c, 'category_ids': class_ids.tolist(), 'boxes': boxes.tolist(), 'scores': scores.tolist()})\n",
        "        # print(img.shape)\n",
        "        result.write(im)\n",
        "        c+=1\n",
        "    print(time.time()-st)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsWf0m9RyVEz"
      },
      "source": [
        "convert the results to geojson for plotting on map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU0FvNFAS97F"
      },
      "outputs": [],
      "source": [
        "# covert function\n",
        "# To Do"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing sorting below"
      ],
      "metadata": {
        "id": "PjIhKh_sLoiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf Yolov5_StrongSORT_OSNet\n",
        "# !git clone --recurse-submodules https://github.com/mikel-brostrom/Yolov5_StrongSORT_OSNet.git\n",
        "# %cd Yolov5_StrongSORT_OSNet\n",
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "6XrZ5mozRjPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Kkx2zW89jq_NETu4u42CFZTMVD5Hwm6e' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Kkx2zW89jq_NETu4u42CFZTMVD5Hwm6e\" -O /content/osnet_x0_25_msmt17.pt && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "ki79nhVGGwwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2uyaJSUP9iJ",
        "outputId": "1f77b427-d4c1-466d-ce53-1b18dcd94acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # limit the number of cpus used by high performance libraries\n",
        "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "# os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "# os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
        "# os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
        "# os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# import sys\n",
        "\n",
        "# if '/content/Yolov5_StrongSORT_OSNet' not in sys.path:\n",
        "#     sys.path.append('/content/Yolov5_StrongSORT_OSNet')\n",
        "# if '/content/Yolov5_StrongSORT_OSNet/strong_sort' not in sys.path:\n",
        "#     sys.path.append('/content/Yolov5_StrongSORT_OSNet/strong_sort')\n",
        "# if '/content/Yolov5_StrongSORT_OSNet/strong_sort/deep/reid' not in sys.path:\n",
        "#     sys.path.append('/content/Yolov5_StrongSORT_OSNet/strong_sort/deep/reid')\n",
        "\n",
        "# import numpy as np\n",
        "# from pathlib import Path\n",
        "# import torch\n",
        "# import torch.backends.cudnn as cudnn\n",
        "\n",
        "# from strong_sort.utils.parser import get_config\n",
        "# from strong_sort.strong_sort import StrongSORT\n",
        "\n",
        "# config_strongsort = '/content/Yolov5_StrongSORT_OSNet/strong_sort/configs/strong_sort.yaml'\n",
        "# # strong_sort_weights='/content/osnet_x0_25_msmt17.pt'\n",
        "# strong_sort_weights=Path('.')/'osnet_x0_25_msmt17.pt'\n",
        "\n",
        "# # device=torch.device('cpu')\n",
        "# device=torch.device(0)\n",
        "# half=False\n",
        "\n",
        "# # initialize StrongSORT\n",
        "# cfg = get_config()\n",
        "# cfg.merge_from_file(config_strongsort)\n",
        "\n",
        "# source = '/content/drive/MyDrive/roxana-charles-st-gopro-capture-sept30'\n",
        "# target = '/content/drive/MyDrive/pLitter/Street/Boston/output'\n",
        "\n",
        "# # if source == target:\n",
        "# #   print('source should not be same as )\n",
        "\n",
        "# if os.path.isfile(source):\n",
        "#   dataset = [os.path.basename(source)]\n",
        "#   source = os.path.dirname(source)\n",
        "# elif os.path.isdir(source):\n",
        "#   dataset = sorted([im for im in os.listdir(source) if im.lower().endswith(('.mp4', '.avi', '.jpg', '.png'))])\n",
        "# else:\n",
        "#   print('please check source is correct')\n",
        "\n",
        "# print(dataset)\n",
        "\n",
        "# with torch.no_grad():\n",
        "\n",
        "#     for fn in dataset[-2:-1]:\n",
        "#       print(fn)\n",
        "#       if fn.lower().endswith(('.mp4', '.avi')):\n",
        "#         strongsort = StrongSORT(\n",
        "#             strong_sort_weights,\n",
        "#             device,\n",
        "#             half,\n",
        "#             max_dist=cfg.STRONGSORT.MAX_DIST,\n",
        "#             max_iou_distance=cfg.STRONGSORT.MAX_IOU_DISTANCE,\n",
        "#             max_age=cfg.STRONGSORT.MAX_AGE,\n",
        "#             n_init=cfg.STRONGSORT.N_INIT,\n",
        "#             nn_budget=cfg.STRONGSORT.NN_BUDGET,\n",
        "#             mc_lambda=cfg.STRONGSORT.MC_LAMBDA,\n",
        "#             ema_alpha=cfg.STRONGSORT.EMA_ALPHA,\n",
        "#         )\n",
        "#         strongsort.model.warmup()\n",
        "#         outputs = []\n",
        "#         prev_frame = None\n",
        "        \n",
        "#         st = time.time()\n",
        "#         vid = cv2.VideoCapture(os.path.join(source, fn))\n",
        "#         width  = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "#         height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "#         fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
        "#         fn_r = os.path.join(target, fn)\n",
        "#         print(fn_r)\n",
        "#         result = cv2.VideoWriter(fn_r, cv2.VideoWriter_fourcc(*'MP4V'), fps, (width, height))\n",
        "#         pred_json = {'video': fn, 'preds': []}\n",
        "#         c = 1\n",
        "#         while True:\n",
        "#             ret, img = vid.read()\n",
        "#             if img is None:\n",
        "#               json.dump(pred_json, open(target+fn.replace('.MP4', '_result.json'), 'w'))\n",
        "#               result.release()\n",
        "#               vid.release()\n",
        "#               break\n",
        "#             preds = model(img, size=1024)\n",
        "#             # class_ids = preds.xyxy[0].cpu().numpy()[:, 5]\n",
        "#             #classes = [preds.names[cls] for cls in class_ids]\n",
        "#             # scores = preds.xyxy[0].cpu().numpy()[:, 4]\n",
        "#             #boxes = preds.xyxy[0].cpu().numpy()[:,:4]\n",
        "#             boxes = preds.xywh[0][0:,:4]\n",
        "#             scores = preds.xywh[0][:, 4]\n",
        "#             class_ids = preds.xywh[0][:, 5]\n",
        "#             # print(xywhs, confs, clss)\n",
        "#             curr_frame = img\n",
        "#             # print(type(img), img.shape)\n",
        "#             if cfg.STRONGSORT.ECC:  # camera motion compensation\n",
        "#               strongsort.tracker.camera_update(prev_frame, curr_frame)\n",
        "#             print(boxes.cpu(), scores.cpu(), class_ids.cpu(), img.shape)\n",
        "#             outputs = strongsort.update(boxes.cpu(), scores.cpu(), class_ids.cpu(), img)\n",
        "#             print(len(outputs))\n",
        "#             if len(outputs)>0:\n",
        "#               im = draw_boxes_on_image(img, boxes, classes, class_ids, scores, use_normalized_coordinates=False, min_score_thresh=.4)\n",
        "#             else:\n",
        "#               im = img\n",
        "#               strongsort.increment_ages()\n",
        "#             pred_json['preds'].append({'frame': c, 'category_ids': class_ids.tolist(), 'boxes': boxes.tolist(), 'scores': scores.tolist()})\n",
        "#             result.write(im)\n",
        "#             c+=1\n",
        "#             prev_frame = curr_frame\n",
        "#         print(time.time()-st)"
      ],
      "metadata": {
        "id": "ZK4aPzfBR1ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd Yolov5_StrongSORT_OSNet\n",
        "# !python track.py --yolo-weights /content/yolov5l.pt --strong-sort-weights osnet_x0_25_msmt17.pt --source /content/drive/MyDrive/roxana-charles-st-gopro-capture-sept30/GH010021.mp4 --save-vid"
      ],
      "metadata": {
        "id": "innJuHTvP2m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # limit the number of cpus used by high performance libraries\n",
        "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "# os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "# os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
        "# os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
        "# os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# import sys\n",
        "\n",
        "# if '/content/Yolov5_StrongSORT_OSNet' not in sys.path:\n",
        "#     sys.path.append('/content/Yolov5_StrongSORT_OSNet')\n",
        "# if '/content/Yolov5_StrongSORT_OSNet/yolov5' not in sys.path:\n",
        "#   sys.path.append('/content/Yolov5_StrongSORT_OSNet/yolov5')\n",
        "# if '/content/Yolov5_StrongSORT_OSNet/strong_sort' not in sys.path:\n",
        "#     sys.path.append('/content/Yolov5_StrongSORT_OSNet/strong_sort')\n",
        "# if '/content/Yolov5_StrongSORT_OSNet/strong_sort/deep/reid' not in sys.path:\n",
        "#     sys.path.append('/content/Yolov5_StrongSORT_OSNet/strong_sort/deep/reid')\n",
        "\n",
        "# import numpy as np\n",
        "# from pathlib import Path\n",
        "# import torch\n",
        "# import torch.backends.cudnn as cudnn\n",
        "\n",
        "# from strong_sort.utils.parser import get_config\n",
        "# from strong_sort.strong_sort import StrongSORT\n",
        "# import logging\n",
        "# from yolov5.models.common import DetectMultiBackend\n",
        "# from yolov5.utils.dataloaders import VID_FORMATS, LoadImages, LoadStreams\n",
        "# from yolov5.utils.general import (LOGGER, check_img_size, non_max_suppression, scale_coords, check_requirements, cv2,\n",
        "#                                   check_imshow, xyxy2xywh, increment_path, strip_optimizer, colorstr, print_args, check_file)\n",
        "# from yolov5.utils.torch_utils import select_device, time_sync\n",
        "# from yolov5.utils.plots import Annotator, colors, save_one_box\n",
        "# from strong_sort.utils.parser import get_config\n",
        "# from strong_sort.strong_sort import StrongSORT\n",
        "\n",
        "\n",
        "# # @torch.no_grad()\n",
        "# with torch.no_grad():\n",
        "\n",
        "#     yolo_weights='/content/yolov5l.pt'\n",
        "#     strong_sort_weights=Path('/content/Yolov5_StrongSORT_OSNet/osnet_x0_25_msmt17.pt')\n",
        "#     config_strongsort='/content/Yolov5_StrongSORT_OSNet/strong_sort/configs/strong_sort.yaml'\n",
        "#     imgsz=(1024, 1024)\n",
        "#     conf_thres=0.25\n",
        "#     iou_thres=0.45\n",
        "#     max_det=1000\n",
        "#     device=0\n",
        "#     classes=None\n",
        "#     agnostic_nms=False\n",
        "#     augment=False\n",
        "#     visualize=False\n",
        "#     update=False\n",
        "#     exist_ok=False\n",
        "#     half=False\n",
        "#     dnn=False\n",
        "#     eval=False\n",
        "\n",
        "#     source = '/content/drive/MyDrive/roxana-charles-st-gopro-capture-sept30'\n",
        "\n",
        "\n",
        "#     # print(torch.device(0))\n",
        "\n",
        "#     device = torch.device(0)\n",
        "#     print(yolo_weights)\n",
        "#     model = DetectMultiBackend(yolo_weights, device=device, dnn=dnn, data=None, fp16=half)\n",
        "#     stride, names, pt = model.stride, model.names, model.pt\n",
        "#     imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
        "\n",
        "#     dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)\n",
        "#     nr_sources = 1\n",
        "#     vid_path, vid_writer, txt_path = [None] * nr_sources, [None] * nr_sources, [None] * nr_sources\n",
        "\n",
        "#     # initialize StrongSORT\n",
        "#     cfg = get_config()\n",
        "#     cfg.merge_from_file(config_strongsort)\n",
        "\n",
        "#     # Create as many strong sort instances as there are video sources\n",
        "#     strongsort_list = []\n",
        "#     for i in range(nr_sources):\n",
        "#         strongsort_list.append(\n",
        "#             StrongSORT(\n",
        "#                 strong_sort_weights,\n",
        "#                 device,\n",
        "#                 half,\n",
        "#                 max_dist=cfg.STRONGSORT.MAX_DIST,\n",
        "#                 max_iou_distance=cfg.STRONGSORT.MAX_IOU_DISTANCE,\n",
        "#                 max_age=cfg.STRONGSORT.MAX_AGE,\n",
        "#                 n_init=cfg.STRONGSORT.N_INIT,\n",
        "#                 nn_budget=cfg.STRONGSORT.NN_BUDGET,\n",
        "#                 mc_lambda=cfg.STRONGSORT.MC_LAMBDA,\n",
        "#                 ema_alpha=cfg.STRONGSORT.EMA_ALPHA,\n",
        "\n",
        "#             )\n",
        "#         )\n",
        "#         strongsort_list[i].model.warmup()\n",
        "#     outputs = [None] * nr_sources\n",
        "\n",
        "#     # Run tracking\n",
        "#     model.warmup(imgsz=(1 if pt else nr_sources, 3, *imgsz))  # warmup\n",
        "#     dt, seen = [0.0, 0.0, 0.0, 0.0], 0\n",
        "#     curr_frames, prev_frames = [None] * nr_sources, [None] * nr_sources\n",
        "#     for frame_idx, (path, im, im0s, vid_cap, s) in enumerate(dataset):\n",
        "#         t1 = time_sync()\n",
        "#         im = torch.from_numpy(im).to(device)\n",
        "#         im = im.half() if half else im.float()  # uint8 to fp16/32\n",
        "#         im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "#         if len(im.shape) == 3:\n",
        "#             im = im[None]  # expand for batch dim\n",
        "#         t2 = time_sync()\n",
        "#         dt[0] += t2 - t1\n",
        "\n",
        "#         # Inference\n",
        "#         visualize = increment_path(save_dir / Path(path[0]).stem, mkdir=True) if visualize else False\n",
        "#         pred = model(im, augment=augment, visualize=visualize)\n",
        "#         t3 = time_sync()\n",
        "#         dt[1] += t3 - t2\n",
        "\n",
        "#         # Apply NMS\n",
        "#         pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
        "#         dt[2] += time_sync() - t3\n",
        "\n",
        "#         # Process detections\n",
        "#         for i, det in enumerate(pred):  # detections per image\n",
        "#             seen += 1\n",
        "#             p, im0, _ = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
        "#             p = Path(p)  # to Path\n",
        "#             # video file\n",
        "#             if source.endswith(VID_FORMATS):\n",
        "#                 txt_file_name = p.stem\n",
        "#                 save_path = str(save_dir / p.name)  # im.jpg, vid.mp4, ...\n",
        "#             # folder with imgs\n",
        "#             else:\n",
        "#                 txt_file_name = p.parent.name  # get folder name containing current img\n",
        "#             curr_frames[i] = im0\n",
        "\n",
        "#             s += '%gx%g ' % im.shape[2:]  # print string\n",
        "#             # imc = im0.copy() if save_crop else im0  # for save_crop\n",
        "\n",
        "#             # annotator = Annotator(im0, line_width=line_thickness, pil=not ascii)\n",
        "#             if cfg.STRONGSORT.ECC:  # camera motion compensation\n",
        "#                 strongsort_list[i].tracker.camera_update(prev_frames[i], curr_frames[i])\n",
        "\n",
        "#             if det is not None and len(det):\n",
        "#                 # Rescale boxes from img_size to im0 size\n",
        "#                 det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "#                 # Print results\n",
        "#                 for c in det[:, -1].unique():\n",
        "#                     n = (det[:, -1] == c).sum()  # detections per class\n",
        "#                     s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
        "\n",
        "#                 xywhs = xyxy2xywh(det[:, 0:4])\n",
        "#                 confs = det[:, 4]\n",
        "#                 clss = det[:, 5]\n",
        "\n",
        "#                 print(xywhs.cpu(), confs.cpu(), clss.cpu())\n",
        "\n",
        "#                 # pass detections to strongsort\n",
        "#                 t4 = time_sync()\n",
        "#                 outputs[i] = strongsort_list[i].update(xywhs.cpu(), confs.cpu(), clss.cpu(), im0)\n",
        "#                 t5 = time_sync()\n",
        "#                 dt[3] += t5 - t4\n",
        "\n",
        "#                 # draw boxes for visualization\n",
        "#                 if len(outputs[i]) > 0:\n",
        "#                     for j, (output, conf) in enumerate(zip(outputs[i], confs)):\n",
        "\n",
        "#                         bboxes = output[0:4]\n",
        "#                         id = output[4]\n",
        "#                         cls = output[5]\n",
        "\n",
        "\n",
        "#             else:\n",
        "#                 strongsort_list[i].increment_ages()\n",
        "#             prev_frames[i] = curr_frames[i]\n",
        "\n",
        "#     # Print results\n",
        "#     t = tuple(x / seen * 1E3 for x in dt)  # speeds per image\n",
        "#     if update:\n",
        "#         strip_optimizer(yolo_weights)  # update model (to fix SourceChangeWarning)"
      ],
      "metadata": {
        "id": "8oGqgTs-xD2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xb_5AfS239Rc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}